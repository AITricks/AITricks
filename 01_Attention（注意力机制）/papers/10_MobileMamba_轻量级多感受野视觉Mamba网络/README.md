# MobileMamba: 轻量级多感受野视觉 Mamba 网络

### 1. 核心思想

本文针对现有轻量级视觉模型在长距离依赖建模和计算效率之间的矛盾，提出了一种名为 **MobileMamba** 的新型轻量级网络架构。其核心创新在于设计了 **多感受野特征交互（MRFFI）** 模块，通过结合 **小波变换增强的 Mamba（WTE-Mamba）** 和 **多核深度卷积（MK-DeConv）**，在保持线性计算复杂度的同时，实现了全局与局部多尺度感受野的有效融合。此外，论文通过精心设计的三阶段网络结构以及训练和推理阶段的优化策略，使 MobileMamba 在 ImageNet-1K 上达到了 83.6% 的 Top-1 准确率，且在推理速度上远超现有的 CNN、ViT 和其他 Mamba 基模型，实现了速度与精度的最佳平衡。

### 2. 背景与动机

* **文本角度总结**：
    在移动设备和资源受限环境中部署高效视觉模型是一个长期需求。现有的轻量级模型主要分为两类：
    1.  **CNN 基模型**（如 MobileNet）：虽然推理速度快、计算量小，但受限于局部感受野，难以捕捉长距离依赖，导致在高分辨率任务中性能受限。
    2.  **ViT 基模型**（如 MobileViT）：具备全局建模能力，但 Attention 机制的二次方计算复杂度 $O(L^2)$ 使得其在处理高分辨率图像时计算成本过高，推理速度较慢。
    
    虽然近期出现的 **状态空间模型（SSM/Mamba）** 引入了线性复杂度的全局建模能力，但现有的轻量级 Mamba 模型（如 EfficientVMamba, LocalVim）主要关注降低 FLOPs，而在实际 GPU/CPU 推理速度（Throughput）上往往不如 CNN 高效，且性能仍有提升空间。因此，本文旨在设计一种既能保持 Mamba 全局建模优势，又能像 CNN 一样高效推理，同时强化局部细节提取的轻量级架构。

* **动机图解分析**：
    * **图 1（Figure 1）：有效感受野（ERF）与性能对比**
        * **Top (ERF 可视化)**：对比了 CNN（局部）、Transformer（全局但稀疏/计算重）、混合架构和 MobileMamba。MobileMamba（图 iv）展示了**全局且密集**的有效感受野，且中心区域响应强烈（高频细节），证明了其兼顾全局与局部的能力。
        * **Bottom (性能 vs FLOPs)**：在相同的 FLOPs 下，MobileMamba（深蓝/红线）的 ImageNet Top-1 准确率显著高于其他所有 SOTA 模型（如 MobileViTv3, EfficientViT, EMO 等）。这直观展示了其优越的**参数效率**。
    * **图 2（Figure 2）：精度 vs 速度对比**
        * **现象**：该图横轴为吞吐量（Images/s），纵轴为准确率。
        * **分析**：MobileMamba 在同等精度下，速度是 LocalVim 的 **21 倍**，是 EfficientVMamba 的 **3.3 倍**。这直接击中了现有 Mamba 模型“理论 FLOPs 低但实测慢”的痛点，证明了其架构设计的**硬件友好性**。

### 3. 主要贡献点

* **[贡献点 1]：提出了 MobileMamba 三阶段网络架构**
    通过实验对比（Fig. 3），作者发现相比于传统的四阶段设计，**三阶段（Three-stage）** 网络在相同的吞吐量下能获得更高的精度（+0.4%）。因此，MobileMamba 采用了三阶段宏观设计，在保证下采样倍率（1/64）的同时减少了特征图尺寸较大的浅层计算量，从而显著提升了推理速度。

* **[贡献点 2]：设计了多感受野特征交互（MRFFI）模块**
    这是 MobileMamba 的核心细粒度创新。MRFFI 将特征通道一分为三，分别处理：
    1.  **全局与高频**：通过 **WTE-Mamba**（小波变换增强 Mamba），利用小波变换提取高频边缘信息，并结合 Mamba 捕捉全局上下文。
    2.  **局部多尺度**：通过 **MK-DeConv**（多核深度卷积），使用不同大小的卷积核（如 3x3, 5x5）并行提取多尺度局部特征。
    3.  **冗余消除**：部分通道直接通过 Identity 映射（不进行计算），以减少高维空间的特征冗余并提升速度。

* **[贡献点 3]：引入了全流程的训练与测试优化策略**
    为了进一步挖掘轻量级模型的潜力，论文引入了两种训练策略：**知识蒸馏（Knowledge Distillation）** 和 **延长训练周期（Extended Epochs, 1000ep）**，显著提升了小模型的性能上限。同时，在测试阶段使用了 **归一化层融合（Normalization Layer Fusion）**，将 BN 层参数融合进卷积层，进一步加速推理。

### 4. 方法细节

* **整体网络架构（对应 Figure 4a & 4b）**：
    
    ![结构图4](https://gitee.com/ChadHui/typora-image/raw/master/cv-image/20251119192541.jpg)
    
    * **宏观流程**：
        1.  **Patch Embed**：输入图像（$H \times W \times 3$）首先经过一个由 3 层卷积组成的 Stem 层（包含步长为 2 的卷积），快速将分辨率下采样至 $H/16 \times W/16$。
        2.  **Stages 1-3**：网络包含三个主要阶段。每个阶段堆叠多个 **MobileMamba Block**。
        3.  **DownSample**：在 Stage 之间，通过步长为 2 的卷积进行下采样，通道数翻倍，分辨率减半。最终输出分辨率为 $H/64 \times W/64$。
        4.  **输出**：最后经过全局平均池化和分类器输出结果。
    
* **核心创新模块详解（MRFFI Module - Figure 4c & 4d）**：

    * **模块 A：MobileMamba Block 结构（Figure 4c）**
        * **组成**：采用了类似 Transformer 的 Meta-Former 结构，包含两个子模块：
            1.  **Local Perceptual**：由前馈网络（FFN）和深度卷积（DWConv）组成，负责基础的局部特征提取。
            2.  **MRFFI**：核心模块，负责多感受野特征交互，外围包裹着残差连接。
        
    * **模块 B：多感受野特征交互 (MRFFI)（Figure 4d）**
        * **内部数据流**：输入特征 $x^I$ 在通道维度被切分为三部分：
            1.  **Part 1 (Global & High-Freq)**：通道占比 $\xi c$。
                * **WTE-Mamba**：这部分特征首先通过双向 Mamba (Bi-Mamba) 提取全局依赖。同时，特征经过 **小波变换 (WT)** 分解为低频和高频分量（尺寸减半，通道 x4），在频域进行卷积处理以捕获大感受野和边缘信息，最后通过 **逆小波变换 (IWT)** 还原。Mamba 的输出与 IWT 的输出相加，得到 $x_G^O$。
            2.  **Part 2 (Local Multi-Scale)**：通道占比 $\mu c$。
                * **MK-DeConv**：这部分特征被进一步拆分为 $n$ 组，每组通过不同大小的卷积核（$k=3, 5, \dots$）进行深度卷积。这种设计模拟了多尺度感受野，输出拼接后得到 $x_L^O$。
            3.  **Part 3 (Identity)**：剩余通道 $(1-\xi-\mu)c$。
                * **Identity**：直接通过，不做任何计算。这基于“高维特征存在冗余”的假设，有效降低了 FLOPs 和内存访问。
            4.  **Fusion**：最后，三部分输出在通道维度拼接，经过 $1\times1$ 卷积融合，得到最终输出 $x^O$。

* **理念与机制总结**：
    * **核心理念**：**“分而治之，各司其职”**。MobileMamba 认为不必对所有通道都进行昂贵的全局建模。它将计算资源分配给最需要的地方：一部分通道负责全局和细节（Mamba+Wavelet），一部分负责多尺度局部（Multi-Kernel Conv），一部分保持原样（Identity）。这种混合策略在极低的计算成本下实现了全方位的特征捕获。
    * **WTE-Mamba 机制**：利用小波变换的下采样特性，在降低分辨率的同时扩大了卷积的有效感受野，并显式地增强了 Mamba 容易忽略的高频纹理信息。

* **图解总结**：
    结合 **Figure 4**，MobileMamba 的设计极其精巧。
    * **Figure 4(a)** 展示了为了速度而采用的激进的 **1/16 起步的三阶段架构**。
    * **Figure 4(d)** 清晰展示了 MRFFI 的三路并行结构。特别是中间的 **WTE-Mamba** 分支，通过 WT/IWT 的漏斗状结构，直观地体现了如何在频域高效处理特征。

### 5. 即插即用模块的作用

MobileMamba 中的核心模块设计具有高度的独立性和通用性，可作为即插即用组件优化其他模型：

1.  **MRFFI 模块 (Multi-Receptive Field Feature Interaction)**
    * **适用场景**：任何需要平衡全局信息与局部细节，且对推理速度敏感的视觉任务。
    * **具体应用**：
        * **替换 Transformer Block**：在 ViT 或 Swin Transformer 中，可以用 MRFFI 替换标准的 Self-Attention 模块。这能显著降低计算量，同时引入卷积的归纳偏置，适合在数据量较小或算力受限的场景下提升性能。
        * **CNN 性能增强**：在 ResNet 或 MobileNet 的深层阶段，插入 MRFFI 模块，利用其 Mamba 分支引入全局感受野，解决 CNN“看不远”的问题。

2.  **WTE-Mamba (Wavelet Transform-Enhanced Mamba)**
    * **适用场景**：对纹理、边缘等高频信息敏感的任务，如**超分辨率**、**去噪**、**医学图像分割**。
    * **具体应用**：小波变换能无损地分离高低频信息。将 WTE-Mamba 作为这些任务的主干单元，可以利用 Mamba 处理全局结构（低频），利用小波卷积处理纹理细节（高频），从而生成更清晰、更锐利的图像结果。

3.  **MK-DeConv (Multi-Kernel Depthwise Convolution)**
    * **适用场景**：需要多尺度特征捕获的轻量级网络头部或特征提取层。
    * **具体应用**：
        * **目标检测 Head**：在 YOLO 或 SSD 的检测头中，使用 MK-DeConv 替代普通的 $3\times3$ 卷积，可以以极小的额外代价让模型同时感知不同大小的物体（如同时检测远处的行人和近处的车辆）。