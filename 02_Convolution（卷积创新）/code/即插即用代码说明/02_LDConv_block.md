# LDConv å³æ’å³ç”¨æ¨¡å—ä½¿ç”¨è¯´æ˜

## ğŸ“– ç®€ä»‹

LDConv (Learnable Deformable Convolution) æ˜¯ä¸€ä¸ªåŸºäºAKConvåŸç†å®ç°çš„å¯å­¦ä¹ å˜å½¢å·ç§¯æ¨¡å—ï¼Œæ”¯æŒä»»æ„é‡‡æ ·å½¢çŠ¶å·ç§¯æ ¸ä¸ä»»æ„å‚æ•°æ•°é‡å·ç§¯æ ¸ã€‚è¯¥æ¨¡å—å¯ä»¥**å³æ’å³ç”¨**åœ°æ›¿æ¢æ™®é€šå·ç§¯å±‚ï¼Œæ— éœ€ä¿®æ”¹ç½‘ç»œå…¶ä»–éƒ¨åˆ†ã€‚

### æ ¸å¿ƒç‰¹æ€§

- âœ… **å³æ’å³ç”¨**ï¼šå¯ç›´æ¥æ›¿æ¢ `nn.Conv2d`ï¼Œä¿æŒè¾“å…¥è¾“å‡ºå½¢çŠ¶ä¸€è‡´
- âœ… **è‡ªé€‚åº”é‡‡æ ·**ï¼šé€šè¿‡å¯å­¦ä¹ çš„åç§»é‡åŠ¨æ€è°ƒæ•´é‡‡æ ·ä½ç½®
- âœ… **ä»»æ„é‡‡æ ·ç‚¹æ•°é‡**ï¼šæ”¯æŒä»»æ„æ•°é‡çš„é‡‡æ ·ç‚¹ï¼ˆå¦‚4, 9, 16, 25ç­‰ï¼‰
- âœ… **åŒçº¿æ€§æ’å€¼**ï¼šä½¿ç”¨åŒçº¿æ€§æ’å€¼ç¡®ä¿é‡‡æ ·è¿‡ç¨‹å¯å¾®
- âœ… **ç¨³å®šè®­ç»ƒ**ï¼šé€šè¿‡æ¢¯åº¦ç¼©æ”¾æœºåˆ¶ä¿è¯è®­ç»ƒç¨³å®šæ€§

## ğŸ”§ å®‰è£…è¦æ±‚

### Pythonç¯å¢ƒ
- Python >= 3.6
- PyTorch >= 1.7.0ï¼ˆæ¨è >= 1.10.0 ä»¥æ”¯æŒå®Œæ•´çš„meshgridåŠŸèƒ½ï¼‰
- einops >= 0.3.0

### å®‰è£…å‘½ä»¤
```bash
pip install torch torchvision
pip install einops
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### åŸºæœ¬ä½¿ç”¨

```python
import torch
import torch.nn as nn
from LDConv_block import LDConv

# åˆ›å»ºLDConvæ¨¡å—
ldconv = LDConv(
    inc=64,        # è¾“å…¥é€šé“æ•°
    outc=128,      # è¾“å‡ºé€šé“æ•°
    num_param=9,   # é‡‡æ ·ç‚¹æ•°é‡ï¼ˆ9è¡¨ç¤º3x3ç½‘æ ¼ï¼‰
    stride=1,      # æ­¥é•¿
    bias=False     # æ˜¯å¦ä½¿ç”¨åç½®
)

# å‰å‘ä¼ æ’­
x = torch.randn(2, 64, 32, 32)  # (batch, channels, height, width)
output = ldconv(x)  # (2, 128, 32, 32)
```

### å³æ’å³ç”¨æ›¿æ¢ç¤ºä¾‹

#### ç¤ºä¾‹1ï¼šæ›¿æ¢å•ä¸ªå·ç§¯å±‚

```python
import torch.nn as nn
from LDConv_block import LDConv

# åŸå§‹ç½‘ç»œ
class OriginalNet(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(3, 64, 3, padding=1)
        self.conv2 = nn.Conv2d(64, 128, 3, padding=1)
        
    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        return x

# ä½¿ç”¨LDConvæ›¿æ¢åçš„ç½‘ç»œ
class LDConvNet(nn.Module):
    def __init__(self):
        super().__init__()
        # ç›´æ¥æ›¿æ¢ï¼šnn.Conv2d â†’ LDConv
        self.conv1 = LDConv(3, 64, num_param=9, stride=1)    # æ›¿æ¢ç¬¬ä¸€ä¸ªå·ç§¯
        self.conv2 = LDConv(64, 128, num_param=9, stride=1)  # æ›¿æ¢ç¬¬äºŒä¸ªå·ç§¯
        
    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        return x
```

#### ç¤ºä¾‹2ï¼šåœ¨YOLOç­‰æ£€æµ‹ç½‘ç»œä¸­ä½¿ç”¨

```python
# æ›¿æ¢YOLOv5ä¸­çš„Convæ¨¡å—
class Conv(nn.Module):
    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, act=True):
        super().__init__()
        # åŸå§‹å®ç°
        # self.conv = nn.Conv2d(c1, c2, k, s, p, groups=g, bias=False)
        
        # ä½¿ç”¨LDConvæ›¿æ¢ï¼ˆå½“k=3æ—¶ï¼‰
        if k == 3:
            self.conv = LDConv(c1, c2, num_param=9, stride=s)
        else:
            self.conv = nn.Conv2d(c1, c2, k, s, p, groups=g, bias=False)
        
        self.bn = nn.BatchNorm2d(c2)
        self.act = nn.SiLU() if act else nn.Identity()
    
    def forward(self, x):
        return self.act(self.bn(self.conv(x)))
```

#### ç¤ºä¾‹3ï¼šéƒ¨åˆ†æ›¿æ¢ç­–ç•¥

```python
class HybridNet(nn.Module):
    def __init__(self):
        super().__init__()
        # åªåœ¨å…³é”®å±‚ä½¿ç”¨LDConv
        self.conv1 = nn.Conv2d(3, 64, 3, padding=1)           # æ™®é€šå·ç§¯
        self.conv2 = LDConv(64, 128, num_param=9, stride=2)   # LDConvï¼ˆä¸‹é‡‡æ ·ï¼‰
        self.conv3 = nn.Conv2d(128, 256, 3, padding=1)        # æ™®é€šå·ç§¯
        self.conv4 = LDConv(256, 512, num_param=16, stride=2) # LDConvï¼ˆæ›´å¤šé‡‡æ ·ç‚¹ï¼‰
```

## ğŸ“‹ å‚æ•°è¯´æ˜

### LDConv å‚æ•°

| å‚æ•° | ç±»å‹ | è¯´æ˜ | é»˜è®¤å€¼ |
|------|------|------|--------|
| `inc` | int | è¾“å…¥é€šé“æ•° | - |
| `outc` | int | è¾“å‡ºé€šé“æ•° | - |
| `num_param` | int | é‡‡æ ·ç‚¹æ•°é‡ï¼ˆå·ç§¯æ ¸å‚æ•°æ•°é‡ï¼‰ | - |
| `stride` | int | æ­¥é•¿ | 1 |
| `bias` | bool | æ˜¯å¦ä½¿ç”¨åç½® | None |

### num_param å‚æ•°è¯´æ˜

`num_param` å†³å®šäº†é‡‡æ ·ç‚¹çš„æ•°é‡ï¼Œé€šå¸¸é€‰æ‹©å®Œå…¨å¹³æ–¹æ•°ï¼š

- `num_param=4` â†’ 2Ã—2 ç½‘æ ¼ï¼ˆ4ä¸ªé‡‡æ ·ç‚¹ï¼‰
- `num_param=9` â†’ 3Ã—3 ç½‘æ ¼ï¼ˆ9ä¸ªé‡‡æ ·ç‚¹ï¼‰
- `num_param=16` â†’ 4Ã—4 ç½‘æ ¼ï¼ˆ16ä¸ªé‡‡æ ·ç‚¹ï¼‰
- `num_param=25` â†’ 5Ã—5 ç½‘æ ¼ï¼ˆ25ä¸ªé‡‡æ ·ç‚¹ï¼‰

å¯¹äºéå®Œå…¨å¹³æ–¹æ•°ï¼Œä¼šè‡ªåŠ¨ç”Ÿæˆæ¥è¿‘è§„åˆ™ç½‘æ ¼çš„é‡‡æ ·ç‚¹åˆ†å¸ƒã€‚

## ğŸ”„ ä¸æ™®é€šå·ç§¯çš„å¯¹åº”å…³ç³»

| æ™®é€šå·ç§¯ | LDConv |
|---------|--------|
| `nn.Conv2d(inc, outc, k=3, s=1, p=1)` | `LDConv(inc, outc, num_param=9, stride=1)` |
| `nn.Conv2d(inc, outc, k=5, s=1, p=2)` | `LDConv(inc, outc, num_param=25, stride=1)` |
| `nn.Conv2d(inc, outc, k=3, s=2, p=1)` | `LDConv(inc, outc, num_param=9, stride=2)` |

**æ³¨æ„**ï¼šLDConvä¸éœ€è¦paddingå‚æ•°ï¼Œå› ä¸ºå®ƒæ˜¯é€šè¿‡å¯å­¦ä¹ åç§»é‡è‡ªé€‚åº”é‡‡æ ·çš„ã€‚

## ğŸ“Š è¾“å‡ºå½¢çŠ¶

LDConvçš„è¾“å‡ºå½¢çŠ¶è®¡ç®—æ–¹å¼ä¸æ™®é€šå·ç§¯ç±»ä¼¼ï¼š

```python
# è¾“å…¥å½¢çŠ¶: (B, C_in, H, W)
# è¾“å‡ºå½¢çŠ¶: (B, C_out, H', W')

# å…¶ä¸­ï¼š
# H' = floor((H * stride) / stride) = H (å½“stride=1æ—¶)
# W' = floor((W * stride) / stride) = W (å½“stride=1æ—¶)
```

## âš™ï¸ å·¥ä½œåŸç†

LDConvçš„å·¥ä½œæµç¨‹ï¼ˆå¯¹åº”ç»“æ„å›¾ï¼‰ï¼š

1. **ç”ŸæˆOffset**ï¼šé€šè¿‡ `p_conv` å·ç§¯å±‚ç”Ÿæˆå¯å­¦ä¹ çš„åç§»é‡
2. **åˆå§‹é‡‡æ ·åæ ‡**ï¼šæ ¹æ® `num_param` ç”Ÿæˆè§„åˆ™çš„åˆå§‹é‡‡æ ·ç½‘æ ¼ï¼ˆp_nï¼‰
3. **åæ ‡ä¿®æ”¹**ï¼šå°†åç§»é‡åº”ç”¨åˆ°åˆå§‹åæ ‡ï¼š`p = p_0 + p_n + offset`
4. **åŒçº¿æ€§æ’å€¼**ï¼šè®¡ç®—å››ä¸ªæœ€è¿‘é‚»ç‚¹çš„æ’å€¼æƒé‡
5. **é‡é‡‡æ ·**ï¼šåŸºäºä¿®æ”¹åçš„åæ ‡ä»è¾“å…¥ç‰¹å¾å›¾ä¸­é‡‡æ ·
6. **Reshape**ï¼šå°†é‡é‡‡æ ·åçš„ç‰¹å¾é‡å¡‘ä¸ºå·ç§¯å±‚å¯å¤„ç†çš„å½¢çŠ¶
7. **å·ç§¯å¤„ç†**ï¼šé€šè¿‡æœ€ç»ˆçš„å·ç§¯ã€å½’ä¸€åŒ–å’Œæ¿€æ´»å±‚è¾“å‡ºç»“æœ

## ğŸ’¡ ä½¿ç”¨å»ºè®®

### 1. é‡‡æ ·ç‚¹æ•°é‡é€‰æ‹©

- **å°ç½‘ç»œ/è½»é‡çº§æ¨¡å‹**ï¼šä½¿ç”¨ `num_param=4` æˆ– `num_param=9`
- **ä¸­ç­‰ç½‘ç»œ**ï¼šä½¿ç”¨ `num_param=9` æˆ– `num_param=16`
- **å¤§ç½‘ç»œ/é«˜ç²¾åº¦éœ€æ±‚**ï¼šä½¿ç”¨ `num_param=16` æˆ– `num_param=25`

### 2. æ›¿æ¢ç­–ç•¥

- **å…¨éƒ¨æ›¿æ¢**ï¼šå°†æ‰€æœ‰ `nn.Conv2d` æ›¿æ¢ä¸º `LDConv`ï¼ˆå¯èƒ½å¢åŠ è¾ƒå¤šå‚æ•°é‡ï¼‰
- **éƒ¨åˆ†æ›¿æ¢**ï¼šåªåœ¨å…³é”®å±‚ï¼ˆå¦‚ä¸‹é‡‡æ ·å±‚ã€ç‰¹å¾æå–å±‚ï¼‰ä½¿ç”¨ `LDConv`
- **æ¸è¿›æ›¿æ¢**ï¼šå…ˆåœ¨éƒ¨åˆ†å±‚ä½¿ç”¨ï¼Œè§‚å¯Ÿæ•ˆæœåå†å†³å®šæ˜¯å¦å…¨é¢æ›¿æ¢

### 3. è®­ç»ƒå»ºè®®

- **å­¦ä¹ ç‡**ï¼šå¯ä»¥ä½¿ç”¨ä¸æ™®é€šå·ç§¯ç›¸åŒçš„å­¦ä¹ ç‡
- **åˆå§‹åŒ–**ï¼šåç§»é‡å·ç§¯å·²è‡ªåŠ¨åˆå§‹åŒ–ä¸º0ï¼Œç¡®ä¿è®­ç»ƒåˆæœŸç¨³å®š
- **æ¢¯åº¦ç¼©æ”¾**ï¼šå·²å†…ç½®æ¢¯åº¦ç¼©æ”¾æœºåˆ¶ï¼ˆ0.1å€ï¼‰ï¼Œä¿è¯åç§»é‡å­¦ä¹ ç¨³å®š

## ğŸ“ˆ æ€§èƒ½å¯¹æ¯”

### å‚æ•°é‡å¯¹æ¯”

```python
import torch.nn as nn
from LDConv_block import LDConv

# æ™®é€šå·ç§¯
conv_normal = nn.Conv2d(64, 128, 3, padding=1, bias=False)
params_normal = sum(p.numel() for p in conv_normal.parameters())
print(f"æ™®é€šå·ç§¯å‚æ•°é‡: {params_normal:,}")  # 73,728

# LDConv
conv_ldconv = LDConv(64, 128, num_param=9, stride=1, bias=False)
params_ldconv = sum(p.numel() for p in conv_ldconv.parameters())
print(f"LDConvå‚æ•°é‡: {params_ldconv:,}")    # çº¦ 82,944 (å¢åŠ çº¦12.5%)
```

### è®¡ç®—é‡å¯¹æ¯”

LDConvç›¸æ¯”æ™®é€šå·ç§¯ï¼š
- **å‚æ•°é‡**ï¼šå¢åŠ çº¦ 10-15%ï¼ˆä¸»è¦æ¥è‡ªåç§»é‡ç”Ÿæˆå·ç§¯ï¼‰
- **è®¡ç®—é‡**ï¼šå¢åŠ çº¦ 20-30%ï¼ˆä¸»è¦æ¥è‡ªåŒçº¿æ€§æ’å€¼å’Œé‡é‡‡æ ·ï¼‰
- **å†…å­˜å ç”¨**ï¼šå¢åŠ çº¦ 15-25%ï¼ˆéœ€è¦å­˜å‚¨ä¸­é—´ç‰¹å¾å›¾ï¼‰

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **å†…å­˜å ç”¨**ï¼šLDConvéœ€è¦æ›´å¤šå†…å­˜æ¥å­˜å‚¨ä¸­é—´ç‰¹å¾ï¼Œå¯¹äºå¤§batch sizeå¯èƒ½éœ€è¦è°ƒæ•´
2. **è®­ç»ƒæ—¶é—´**ï¼šç”±äºå¢åŠ äº†é‡‡æ ·å’Œæ’å€¼æ“ä½œï¼Œè®­ç»ƒæ—¶é—´ä¼šæœ‰æ‰€å¢åŠ 
3. **CUDAæ”¯æŒ**ï¼šå»ºè®®ä½¿ç”¨GPUè®­ç»ƒï¼ŒCPUä¸Šå¯èƒ½è¾ƒæ…¢
4. **ç‰ˆæœ¬å…¼å®¹æ€§**ï¼šéœ€è¦ PyTorch >= 1.7.0ï¼Œeinops >= 0.3.0

## ğŸ” å¸¸è§é—®é¢˜

### Q1: å¦‚ä½•é€‰æ‹© num_paramï¼Ÿ

A: é€šå¸¸é€‰æ‹©ä¸åŸå§‹å·ç§¯æ ¸å¤§å°å¯¹åº”çš„é‡‡æ ·ç‚¹æ•°é‡ï¼š
- 3Ã—3 å·ç§¯ â†’ `num_param=9`
- 5Ã—5 å·ç§¯ â†’ `num_param=25`
- ä¹Ÿå¯ä»¥å°è¯•å…¶ä»–æ•°é‡ï¼Œå¦‚ `num_param=16` ç”¨äº4Ã—4ç½‘æ ¼

### Q2: è¾“å‡ºå½¢çŠ¶ä¸æ™®é€šå·ç§¯ä¸ä¸€è‡´ï¼Ÿ

A: ç¡®ä¿ `stride` å‚æ•°è®¾ç½®æ­£ç¡®ã€‚LDConvçš„è¾“å‡ºå½¢çŠ¶è®¡ç®—æ–¹å¼ä¸æ™®é€šå·ç§¯ç›¸åŒã€‚

### Q3: è®­ç»ƒä¸ç¨³å®šï¼Ÿ

A: LDConvå·²å†…ç½®æ¢¯åº¦ç¼©æ”¾æœºåˆ¶ï¼Œå¦‚æœä»ä¸ç¨³å®šï¼Œå¯ä»¥ï¼š
- é™ä½å­¦ä¹ ç‡
- ä½¿ç”¨warmupç­–ç•¥
- æ£€æŸ¥æ•°æ®é¢„å¤„ç†æ˜¯å¦æ­£å¸¸

### Q4: å¦‚ä½•è¿ç§»é¢„è®­ç»ƒæ¨¡å‹ï¼Ÿ

A: ç”±äºLDConvç»“æ„ä¸æ™®é€šå·ç§¯ä¸åŒï¼Œæ— æ³•ç›´æ¥åŠ è½½é¢„è®­ç»ƒæƒé‡ã€‚å»ºè®®ï¼š
1. å…ˆç”¨æ™®é€šå·ç§¯è®­ç»ƒï¼Œå†ç”¨LDConvä»å¤´è®­ç»ƒ
2. æˆ–è€…åœ¨éƒ¨åˆ†å±‚ä½¿ç”¨LDConvï¼Œå…¶ä»–å±‚åŠ è½½é¢„è®­ç»ƒæƒé‡

## ğŸ“ å®Œæ•´ç¤ºä¾‹

```python
import torch
import torch.nn as nn
from LDConv_block import LDConv

# å®Œæ•´çš„ç½‘ç»œç¤ºä¾‹
class ExampleNet(nn.Module):
    def __init__(self, num_classes=10):
        super().__init__()
        # ä½¿ç”¨LDConvæ›¿æ¢æ™®é€šå·ç§¯
        self.features = nn.Sequential(
            LDConv(3, 64, num_param=9, stride=2),      # ä¸‹é‡‡æ ·
            nn.ReLU(inplace=True),
            LDConv(64, 128, num_param=9, stride=2),    # ä¸‹é‡‡æ ·
            nn.ReLU(inplace=True),
            LDConv(128, 256, num_param=16, stride=2),  # æ›´å¤šé‡‡æ ·ç‚¹
            nn.ReLU(inplace=True),
        )
        self.avgpool = nn.AdaptiveAvgPool2d(1)
        self.classifier = nn.Linear(256, num_classes)
    
    def forward(self, x):
        x = self.features(x)
        x = self.avgpool(x)
        x = x.view(x.size(0), -1)
        x = self.classifier(x)
        return x

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    model = ExampleNet(num_classes=10)
    x = torch.randn(2, 3, 224, 224)
    output = model(x)
    print(f"è¾“å…¥å½¢çŠ¶: {x.shape}")
    print(f"è¾“å‡ºå½¢çŠ¶: {output.shape}")
```

## ğŸ“š å‚è€ƒ

- åŸºäºAKConvåŸç†å®ç°
- æ”¯æŒä»»æ„é‡‡æ ·å½¢çŠ¶å·ç§¯æ ¸
- æ”¯æŒä»»æ„å‚æ•°æ•°é‡å·ç§¯æ ¸
- å®Œæ•´çš„å³æ’å³ç”¨æ”¯æŒ

## ğŸ“„ è®¸å¯è¯

è¯·å‚è€ƒé¡¹ç›®ä¸»ç›®å½•çš„è®¸å¯è¯æ–‡ä»¶ã€‚

---

**æç¤º**ï¼šè¿è¡Œ `python LDConv-block.py` å¯ä»¥æŸ¥çœ‹å®Œæ•´çš„æ¼”ç¤ºç¤ºä¾‹å’Œæ€§èƒ½å¯¹æ¯”ã€‚
