## DAT 即插即用模块 使用说明

本说明针对仓库中的即插即用测试脚本 `test_dat_plug_and_play.py`，帮助你在独立脚本中快速体验模块，或将模块集成进你的网络中。

### 1. 环境与依赖
- **Python**: 3.8+
- **PyTorch**: 1.10+（建议与本机 CUDA 版本匹配）
- 依赖包：`einops`

安装依赖（建议先创建虚拟环境）：

```bash
pip install -r requirements.txt
```

如需手动安装关键依赖：

```bash
pip install torch einops
```

在 Windows PowerShell 中运行命令与上述相同。

### 2. 代码位置
- 即插即用测试与模块封装文件：`test_dat_plug_and_play.py`

该文件内包含三类可直接对图像张量进行前向的包装层：
- `SGFN_Wrapper`（空间门控前馈网络）
- `Adaptive_Channel_Attention_Wrapper`（自适应通道注意力）
- `Adaptive_Spatial_Attention_Wrapper`（自适应空间注意力，含可选窗口平移与相对位置偏置）

### 3. 快速开始（直接运行测试）
在项目根目录执行：

```bash
python test_dat_plug_and_play.py
```

脚本会依次对三种模块进行随机输入测试，并验证输入/输出形状一致（形状断言）。脚本中已对包含 BatchNorm 的分支在测试时显式 `eval()`，避免 batch size=1 造成统计量错误。

期望输出示例（简化）：

```
============================================================
测试 SGFN
============================================================
输入形状: torch.Size([1, 32, 256, 256])
输出形状: torch.Size([1, 32, 256, 256])
...
```

### 4. API 说明（包装类，图像格式输入输出）

所有包装类均接受形如 `B×C×H×W` 的输入，内部会在序列与图像表示之间进行转换，输出形状与输入一致。

- `SGFN_Wrapper(channel, hidden_features=None, act_layer=nn.GELU, drop=0.)`
  - 作用：空间门控前馈网络（SGFN）；对每个位置进行前馈并含空间门控。
  - 关键参数：
    - `channel`: 输入/输出通道数 C。
    - `hidden_features`: 隐藏维度，默认 `4*C`。
    - `act_layer`: 激活函数，默认 `GELU`。
    - `drop`: Dropout 比例。

- `Adaptive_Channel_Attention_Wrapper(channel, num_heads=8, qkv_bias=False, qk_scale=None, attn_drop=0., proj_drop=0.)`
  - 作用：多头通道注意力 + 深度可分离卷积分支，含通道/空间交互映射并进行融合。
  - 关键参数：
    - `channel`: 输入/输出通道数 C。
    - `num_heads`: 注意力头数（须整除 C）。
    - `attn_drop`/`proj_drop`: 注意力/投影 Dropout。

- `Adaptive_Spatial_Attention_Wrapper(channel, num_heads=8, reso=64, split_size=[8,8], shift_size=[1,2], qkv_bias=False, qk_scale=None, drop=0., attn_drop=0., rg_idx=0, b_idx=0)`
  - 作用：自适应空间注意力（窗口划分，双分支互换 H/W 维度的空间注意），可选平移窗口与动态相对位置偏置，融合卷积分支及通道/空间交互。
  - 关键参数：
    - `channel`: 输入/输出通道数 C。
    - `num_heads`: 注意力头数（每个空间分支使用 `num_heads/2`）。
    - `reso`: 训练/参考的基础分辨率（影响掩码缓存）。
    - `split_size`: 窗口大小 `[h, w]`。
    - `shift_size`: 窗口平移 `[sh, sw]`，需满足 `0 <= sh < h` 且 `0 <= sw < w`。
    - `rg_idx, b_idx`: 用于决定是否启用带平移的掩码（复现论文中交替布置策略时使用）。

### 5. 最小使用示例（集成至你的网络）

```python
import torch
import torch.nn as nn
from test_dat_plug_and_play import (
    SGFN_Wrapper,
    Adaptive_Channel_Attention_Wrapper,
    Adaptive_Spatial_Attention_Wrapper,
)

class TinyBlock(nn.Module):
    def __init__(self, channels: int = 32):
        super().__init__()
        self.sgfn = SGFN_Wrapper(channel=channels, hidden_features=channels * 4)
        self.chan_attn = Adaptive_Channel_Attention_Wrapper(channel=channels, num_heads=8)
        self.spa_attn = Adaptive_Spatial_Attention_Wrapper(channel=channels, num_heads=8, reso=256,
                                                           split_size=[8, 8], shift_size=[1, 2])

    def forward(self, x: torch.Tensor) -> torch.Tensor:  # x: [B, C, H, W]
        x = self.sgfn(x)
        x = self.chan_attn(x)
        x = self.spa_attn(x)
        return x

if __name__ == "__main__":
    model = TinyBlock(32).eval()  # 含 BN 的模块在推理时请使用 eval()
    inp = torch.randn(1, 32, 256, 256)
    out = model(inp)
    print(out.shape)
```

要点：
- 输入输出均为 `B×C×H×W`；确保 `num_heads` 能整除 `channel`。
- 若 batch 很小（如 1），包含 BatchNorm 的分支在测试/推理时应 `eval()`。

### 6. 参数与形状约束小结
- 形状：`[B, C, H, W]` -> `[B, C, H, W]`，保持不变。
- `Adaptive_Spatial_Attention_Wrapper` 内部会对 `H/W` 做必要 padding 以适配 `split_size`；输出会裁回原尺寸。
- `num_heads` 与 `channel`：`channel % num_heads == 0`。

### 7. 常见问题
- 运行时报 BN 相关错误：
  - 将模块或模型置为 `eval()`，或使用更大的 batch size；脚本示例已对测试模块使用 `eval()`。
- 分辨率与窗口不整除：
  - 内部已自动 padding；如需固定窗口对齐，可设定 `H/W` 为 `split_size` 的倍数。
- CUDA 相关错误：
  - 确认已安装与显卡/驱动匹配的 PyTorch CUDA 版本；或先在 CPU 上验证。

### 8. 在你现有工程中的引入方式
- 直接复制 `test_dat_plug_and_play.py` 中对应类到你的项目模块文件，或将该文件作为依赖导入。
- 按“最小使用示例”接入你的骨干网络（backbone）或 head/neck 模块中。

### 9. 版权与引用
- 项目 License 见 `LICENSE`。
- 如用于学术研究或复现，请在论文中提及 DAT 相关工作并遵循仓库引用方式。

如有问题，欢迎在仓库提交 Issue，或在脚本基础上添加更详细的单元测试用例。


